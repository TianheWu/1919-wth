## 周报14 

### 遗留问题的思考

上周周末，我复现完SRCNN后，发现效果并不是很优秀，在上周周报中也写到了。本周前期，我仔细读了论文发现作者对数据处理部分与我写的有所不同，作者是将每张图片随机截取`32 x 32`大小若干张送进网络进行学习，而我是仅仅将91张图送进去，数据量有明显的变化。而当我重新处理数据后再进行训练，对于图片放大后还是很模糊。

#### 偶然尝试明白了原因

然而当我将图片放大5倍以上后，效果非常的优秀，可以看到相比传统方法，SRCNN利用卷积操作起到了平滑图片，降噪等作用。之前对于仅放大1.2倍和1.5倍的图片，经过SRCNN后图片更加模糊的原因我认为是过度平滑导致的，而造成这样的原因是因为我在预处理的过程中加入了大量的高斯噪音，大量的高斯噪音使网络不得不过度平滑从而消除噪音，以使得恢复出的图片与label图尽可能相似。然而，我们真实的测试集它们并没有加入大量的高斯噪音，我们的网络在进行测试的过程中还是会对其进行过度平滑，从而导致了上周跑出的效果并不好。而利用传统方法放大5倍以上后，图片由于放大，本身就是会多出很多噪音。这样的`scale_size`符合训练网络时采用的数据集，因此测试效果会更好。

![6db49bb10778113d72ef9da17db768b.png](assets/6db49bb10778113d72ef9da17db768b-20211107145336-oyiix8y.png)![7e002159e4bc6535fc695fbc6906b1d.png](assets/7e002159e4bc6535fc695fbc6906b1d-20211107145351-k8sm2eq.png)

### 本周主要工作

由于自己的代码能力还没有达到研究生的标准，本周继续在强化自己的代码能力的基础上进行学习。强化代码能力最快的方法就是手动复现论文。

第一个主要工作是学习GAN网络。GAN从原本的图像生成，到后续其功能在各个领域都有很强大的用途，我们可以用GAN做很多事情。在超分领域中，目前有SRGAN和ESRGAN（后期会读到相应的论文，目前只是略知一二），而利用GAN的思想我们是不是可以对带噪音的图，生成不带噪的图片？可以将很多任务由从网络学习一种处理方法转变为“**不用处理，直接生成**”的思路。

本周尝试从小项目入手，熟悉并掌握了GAN的网络结构，训练模式，以及最重要的loss是如何制定的，并对照着论文中的网络架构图自己搭建GAN网络。

#### GAN

GAN是由两个网络构成的，一个是`Generator`和`Discriminator`，由生成器去生成数据，再由判别器进行打分，并告诉生成器该如何提高。直到生成器能够生成足够优秀的样本数据。

![image.png](assets/image-20211107130008-bt94g4p.png)

上图是一篇利用GAN做图像配准的工作的论文中截取下来的。在复现的过程中遇到了一些问题，后来都稳步解决了：例如在做降采样的时候采取什么方式好，是用卷积做下采样，还是用池化做下采样？以及从卷积层传入全连接层时的`input_size`该如何确定，仿射变换等等一系列问题。

这里针对用哪种方式做下采样提出一下自己的**观点**：

```python
def downsample(in_channels, out_channels, kernel_size=2, stride=1):
    """downsample layer used conv2d"""
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size, stride),
        nn.BatchNorm2d(out_channels)
    )
```

对于池化操作，一般大家都用`maxpooling`，也就是从一个patch中提取最大值，这种池化操作我认为本质是一种**降维提取特征**的思想，它会过滤掉特征周围的信息。但是如果遇到一个patch中同时具有两个相近的值，通过池化操作后也许会过滤到“有用信息”，也就是关键信息被过滤掉了，可能对结果有不利的影响。但是池化操作效率更高，运算速度更快，如果要追求速度的话仅做池化操作即可。

而卷积操作是从一个patch中通过**信息融合**的方式进行提取特征，将周围的信息都利用上了，进行下采样的时候每一个patch的感受野会更大一些，对于需要全局信息的任务是可靠的。但是相比池化操作速度会慢一些。

由于上述网络结构不是很复杂，由很多个`block`堆叠而成，对于图像配准这样全局信息任务较重的我选用的是卷积操作做下采样。下图是复现代码的部分截图。

![image.png](assets/image-20211107142609-qmyn9i4.png)

第二个主要工作是精读了FSRCNN论文。也是入门超分领域必读的文章之一。在阅读这篇论文中我理解了作者是如何从传统方法逐渐过渡到深度学习方法，从而提高网络运行效率和准确度。

#### FSRCNN

![image.png](assets/image-20211107151332-69xnnu5.png)

FSRCNN我还没有进行复现，下周的主要工作就是对FSRCNN进行研究，因此该部分的理解和代码工作下周再进行思考。