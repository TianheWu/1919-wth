## 周报19

### 本周主要工作

本周的主要工作是读了3篇关于IQA的论文，对IQA领域有了更深刻的思考，明确了对几个对（**Learning Conditional Knowledge Distillation for Degraded-ReferenceImage Quality Assessment**）这篇文章可继续深入研究的地方。同时读懂了Transformer的代码，有助于后续任务进行。

### Perceptual Image Quality Assessment with Transformers

这篇文章是2021年CVPR的一篇workshop，提出了**IQT**模型，在NTIRE2021中夺得了第一。

![image.png](assets/image-20211208114154-5ikpag9.png)

该文章本质是在全参考图像质量评价中首次引入了transformer，并以CNN作为backbone从参考图和失真图像中提取感知特征，并对其作差得到特征差异图`F_diff`。然后利用（1x1）的Conv2d进行降维压缩，然后对patches进行了平铺，添加上了额外的quality embedding，和位置编码，送入VIT。最后通过MLP-Head计算最终的质量预测（其中输入为编码器输出的第一个向量）。

该文章里有一些技术细节需要思考，并和师兄进行讨论，例如：

* 在上周周报中提到的，是否可以引入**Vision Transformer with Progressive Sampling (ICCV2021)**该文章中的transformer的分块优化方法对VIT优化，该优化是否能提高IQT的任务。
* 在VIT中为何要在头部引入一个Quaility和Position Embedding。
* 以及为何要用decoder output的第一个输出向量送入MLP-Head（文章中说第一个向量包含了更多的quaility information）。

### MUSIQ: Multi-scale Image Quality Transformer

这篇文章是ICCV2021的一篇文章，它主要是解决了多尺度下图像质量检测的问题。

这篇文章开头主要是介绍了在CNN-based models中总是要对图片进行resize或者crop操作来达到固定图片大小，从而能适应CNN的训练。但是这样的操作会导致图片质量的降低。因此，作者就想到了能够处理任意数量patches的Transformer，由此设计了下图的MUSIQ结构。

![image.png](assets/image-20211210002028-tlmgvw6.png)

该结构的改进主要分为三部分：

* 作者添加了Patch Encoding层，该层能够将多尺度（包含细粒度和粗粒度）的patches提取出来。
* 作者添加了一个Hash-based Embedding。该部分是整个结构最终要的部分。该部分的改进源自于原始的positional embedding是独立的，没有办法使多个scale的patches对齐。
  * 使用这个模块能够使让不同横纵比以及分辨率的图像进行有效编码
  * 在编码的过程中使得多尺度的patches获得close embedding
* 作者为了区分patches是来自不同scale的图片，添加了可学习的Scale Embedding层。

在我看来该结构不仅仅可以应用在IQA上，因为该结构解决的本质问题是融合了不同scale，不同resolution，以及不同横纵比的图片。其实可以尝试将这个结构作为一个像Resnet一样的预训练模型，辅助于下游任务。

### Learning Conditional Knowledge Distillation for Degraded-ReferenceImage Quality Assessment

![image.png](assets/image-20211211180043-uhllaxq.png)

这篇文章的出发点是：现有的FR-IQA的算法并不能应用于blind image restoration，因为真实世界中很少有原始图像是很难获得的。因此，这篇文章主要聚焦于不依赖原始图像去评估IR models。作者发现即使是降质的图片也包含了很多有用的图像先验信息。

作者尝试了直接利用degraded image替代pristine-quality image，结果发现SRCC降低了0.1239。因此设计了如下结构去解决这个问题：

![image.png](assets/image-20211210150400-an8lyve.png)

该论文中网络的结构包含三个模块：

* degradation-tolerant embedding module (DTE)
  * DTE模块主要是用来从degraded图片中捕获参考信息的，作者的想法是从原始图像中学习参考信息，并利用知识蒸馏的方式去引导DTE。
* quality-sensitive embedding module (QSE)
  * QSE模块主要作用是来提取区别特征。
* convolutional score predictor（CSP）
  * CSP模块的作用是和FR-IQA一样，将特征映射为分数。

我认为该文章的研究性更强。一是因为它是第一个用降质图像作为reference image的，这是其他人都没有尝试过的。其次，它的应用场景，意义，更广泛。因为在现实生活中我们确实没有足够的pristine-quality image让我们去参考。第三，该文章所搭建的结构比较简单，如果我们更换其结构，或者不利用知识蒸馏的方式对degraded image与pristine-quality image进行交互，采用新的方式也许效果会更佳？亦或者直接抛弃掉pristine-quality image，在degraded image上进行特征提取？