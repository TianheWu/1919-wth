## 周报17

### 本周主要工作

本周主要工作是将毕设的实验继续跑全，将实验结果整理好。同时完成了学校那边工作实习的任务。读了一篇论文，主要讲述的是SRGAN。这篇周报就讲讲我对SRGAN的理解。

### SRGAN

#### 综述

在之前的SRCNN和FSRCNN中有一个问题存在，就是图像的纹理部分是很模糊的。因此，SRGAN主要解决的问题是恢复图像的高频信号，也就是图像的纹理细节。

#### 提出问题

作者先提出了利用MSE和PSNR去捕捉高质感细节是十分有限的。PSNR并不能从感官层面体现超分辨率，如下图所示。

![image.png](assets/image-20211128195842-hsjhyn7.png)

而作者的工作聚焦在两个方面，一个是向任务中引入GAN，还有一个是引入loss。loss是网络学习的灵魂，当我们不知道该如何从网络结构入手时，想一想**是不是可以从loss**入手？因为超分的效果好不好主要取决于人为感知，因此作者就在`Perceptual loss function`上着手去做实验。

#### Perceputal loss function

作者的loss是这样设置的

![image.png](assets/image-20211128225844-vc3jwy1.png)

作者将loss分为两部分，一部分是`content loss`还有一部分是`adversarial loss`。

##### Content loss

在content loss中，作者借用了`MSE loss`和`VGG loss`的思路构建了如下loss，本质就是对低分辨率图片送入VGG网络，然后利用MSE的算法计算出loss。在这里我去搜了一下为什么感知损失一般都用VGG loss，在网上也找了很多解答，基本没有从原理去阐述的，是因为VGG在ImageNet训练集中，预训练模型相比Resnet跑分更高。

![image.png](assets/image-20211128231934-zf1bcoz.png)

##### Adversarial loss

adversarial loss就是生成器的loss。

![image.png](assets/image-20211129021122-flsxats.png)

在读论文的过程中，看到这里我和书玮师兄有所交流。主要就是谈目前该领域内有没有在loss上有所创新的。后来发现，目前顶会中的论文的loss大多都是东拼西凑，所创新出的loss无疑是几种loss的结合产物。

#### 检测方法

![image.png](assets/image-20211129021658-5ugr9yj.png)

该生成器网络利用了resnet的残差连接的方式进行提取特征，再放入卷积网络最后生成出一张图片，并利用判别器进行真假检验。

在和师兄沟通的时候也引出了一个新的话题，就是对结果的验证工作**IQA**。在这篇文章中，作者做的是**MOS testing**去检验不同的方法进行超分后的效果，MOS分数越高，效果越好。而组里之前做过的一篇有关IQA的工作，后面有很多future work没有来的及实现。目前师兄打算是在这个方向冲一下22年5月份的ACM-mm，正在商讨可以在这个方向做哪些任务，做哪些突破。目前要做的就是收集一下近几年相关的工作。

### 下周工作

下周打算整理一下已经做过的实验，为毕设的论文撰写做一些准备。同时，整理一下近3年来关于做Image Quality Assessment的顶会文章，做好releated work的工作。